{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseball Hall of Fame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we get started, you'll need to follow the below steps to create the players_db database and create the tables:\n",
    "1. Open **PostgreSQL** (You may be asked to enter your password. Please enter your password.)\n",
    "2. Right click on **Databases**, select **Create** and then **Database**.\n",
    "3. Enter **players_db** as the database name and click **Save**.\n",
    "4. Select the players_db database to make the connection active.\n",
    "5. Right click on players_db and select **Query Tool**.\n",
    "6. Open the **schema.sql** file found in the *Resources* folder.\n",
    "7. Run the queries to create the two tables (players and hall_of_fame).\n",
    "8. Make sure your **config.py** file is updated with your username and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from config import username, password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where did we find our data?\n",
    "\n",
    "We found our two CSV files on Kraggle:\n",
    "\n",
    "players: https://www.kaggle.com/seanlahman/the-history-of-baseball?select=player.csv \\\n",
    "hall of fame: https://www.kaggle.com/seanlahman/the-history-of-baseball?select=hall_of_fame.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CSVs into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract players CSV into dataframe\n",
    "\n",
    "csv_file = \"Resources/player.csv\"\n",
    "player_data_df = pd.read_csv(csv_file)\n",
    "player_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hall of fame CSV into dataframe\n",
    "\n",
    "csv_file = \"Resources/hall_of_fame.csv\"\n",
    "hof_data_df = pd.read_csv(csv_file)\n",
    "hof_data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Process:\n",
    "- Downloaded CSV files from Kraggle\n",
    "- Extracted both CSV files into two separate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform player DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_player = player_data_df[[\"player_id\",\"name_first\",\"name_last\",\"birth_country\",\"debut\",\"final_game\"]]\n",
    "\n",
    "transformed_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform hall of fame DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_HOF = hof_data_df[[\"player_id\",\"yearid\",\"inducted\"]]\n",
    "\n",
    "transformed_HOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Process:\n",
    "- Established player_id as the primary key for both datasets\n",
    "- Removed unncessary columns from both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"<username>:<password>@localhost:5432/players_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataFrames into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_player.to_sql(name='players', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_HOF.to_sql(name='hall_of_fame', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm data has been added by querying the players table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from players', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm data has been added by querying the hall of fame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from hall_of_fame', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Process:\n",
    "- Created a connection to PostgreSQL\n",
    "- Confirmed the table names already exist\n",
    "- Loaded each dataframe separately to its appropriate table\n",
    "- Ran two simple queries to confirm both dataframes loaded into the database as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we choose PostgreSQL?\n",
    "\n",
    "We chose PostgreSQL because we were most comfortable utilizing this sort of database as one of us has experience with SQLServer and the two are very similar. Also with data coming from multiple sources, using a relational database in order to join the two datasets together seemed like the best approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we choose baseball player and hall of fame data?\n",
    "\n",
    "After looking through random collections on Kraggle, the baseball collection had the most data to choose from. We looked through many files to figure out which two datasets would compliment each other and landed on the Players and Hall of Fame datasets. They both had the same player_id field which would be beneficial when joining the tables together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
